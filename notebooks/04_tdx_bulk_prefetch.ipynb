{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TripScore â€” TDX Bulk Prefetch (Stageable Full Dataset Download)\n",
        "\n",
        "This notebook demonstrates how to **gradually** fetch full TDX datasets (paged OData) and **resume** later.\n",
        "\n",
        "Key ideas:\n",
        "- Each run fetches only a small number of pages (or uses a time budget), so you can run it repeatedly.\n",
        "- Progress is persisted under the cache directory (default: `.cache/tripscore/tdx_bulk/`).\n",
        "- This is designed to be gentle with TDX rate limits (global request spacing + retries + stale-if-error).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "repo_root = Path.cwd()\n",
        "src_dir = repo_root / \"src\"\n",
        "if src_dir.exists():\n",
        "    sys.path.insert(0, str(src_dir))\n",
        "\n",
        "try:\n",
        "    from tripscore.core.env import load_dotenv_if_present\n",
        "\n",
        "    load_dotenv_if_present()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "print(\"TDX_CLIENT_ID configured:\", bool(os.getenv(\"TDX_CLIENT_ID\")))\n",
        "print(\"TDX_CLIENT_SECRET configured:\", bool(os.getenv(\"TDX_CLIENT_SECRET\")))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tripscore.config.settings import get_settings\n",
        "from tripscore.core.env import resolve_project_path\n",
        "from tripscore.ingestion.tdx_bulk import bulk_prefetch_all\n",
        "from tripscore.ingestion.tdx_client import TdxClient\n",
        "from tripscore.recommender.recommend import build_cache\n",
        "\n",
        "settings = get_settings()\n",
        "cache = build_cache(settings)\n",
        "tdx = TdxClient(settings, cache)\n",
        "\n",
        "cache_dir = resolve_project_path(settings.cache.dir)\n",
        "print(\"TDX city:\", settings.ingestion.tdx.city)\n",
        "print(\"Cache dir:\", cache_dir)\n",
        "print(\"Bulk dir:\", cache_dir / \"tdx_bulk\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run one \"stage\" (repeatable)\n",
        "\n",
        "Re-run this cell as many times as you want. Each run fetches only a small amount.\n",
        "\n",
        "Tips:\n",
        "- If you keep hitting `429`, increase `ingestion.tdx.request_spacing_seconds` in `src/tripscore/config/defaults.yaml`.\n",
        "- You can also lower `ingestion.tdx.retry.max_attempts` to avoid long notebook waits.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets = [\n",
        "    \"bus_stops\",\n",
        "    \"bike_stations\",\n",
        "    \"bike_availability\",\n",
        "    \"metro_stations\",\n",
        "    \"parking_lots\",\n",
        "    \"parking_availability\",\n",
        "]\n",
        "\n",
        "try:\n",
        "    results = bulk_prefetch_all(\n",
        "        tdx_client=tdx,\n",
        "        cache=cache,\n",
        "        city=settings.ingestion.tdx.city,\n",
        "        datasets=datasets,\n",
        "        max_pages_per_dataset=1,\n",
        "        max_seconds_total=20,\n",
        "        reset=False,\n",
        "    )\n",
        "    for r in results:\n",
        "        status = \"done\" if r.done else f\"next_skip={r.next_skip}\"\n",
        "        print(f\"{r.dataset}/{r.scope}: pages={r.pages_fetched} added={r.items_added} total={r.total_items} {status}\")\n",
        "        print(f\"  data: {r.data_path}\")\n",
        "        print(f\"  progress: {r.progress_path}\")\n",
        "except Exception as e:\n",
        "    print(\"Bulk prefetch failed:\", type(e).__name__, str(e))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect progress\n",
        "\n",
        "Progress files track `next_skip` and `done` so the next run can resume.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "def read_progress_files(cache_dir: Path) -> list[dict]:\n",
        "    out = []\n",
        "    base = cache_dir / \"tdx_bulk\"\n",
        "    if not base.exists():\n",
        "        return out\n",
        "    for p in sorted(base.rglob(\"*.progress.json\")):\n",
        "        try:\n",
        "            out.append({\"path\": str(p), **json.loads(p.read_text(encoding=\"utf-8\"))})\n",
        "        except Exception:\n",
        "            continue\n",
        "    return out\n",
        "\n",
        "\n",
        "for row in read_progress_files(cache_dir):\n",
        "    print(row[\"dataset\"], row[\"scope\"], \"done=\", row.get(\"done\"), \"next_skip=\", row.get(\"next_skip\"), \"path=\", row[\"path\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reset (optional)\n",
        "\n",
        "If you want to start over for selected datasets, run with `reset=True`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# WARNING: This deletes only the bulk-prefetch data/progress files for the selected datasets.\n",
        "#\n",
        "# results = bulk_prefetch_all(\n",
        "#     tdx_client=tdx,\n",
        "#     cache=cache,\n",
        "#     city=settings.ingestion.tdx.city,\n",
        "#     datasets=[\"bus_stops\"],\n",
        "#     max_pages_per_dataset=1,\n",
        "#     max_seconds_total=10,\n",
        "#     reset=True,\n",
        "# )\n",
        "# print(results)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
